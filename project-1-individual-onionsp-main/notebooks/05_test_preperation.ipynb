{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c6c25a",
   "metadata": {},
   "source": [
    "# 2025 Test Data Preprocessing\n",
    "\n",
    "This notebook preprocesses 2025 taxi data (Jan-June) for out-of-sample testing of our service consistency models trained on 2024 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0b1f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/15 14:30:20 WARN Utils: Your hostname, Jordans-MBP.local, resolves to a loopback address: 127.0.0.1; using 10.0.9.9 instead (on interface en0)\n",
      "25/08/15 14:30:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/15 14:30:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TLC_2025_Test_Data_Preprocessing\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b7c36",
   "metadata": {},
   "source": [
    "## Load 2025 Raw Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d071c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2025-01: 3,475,226 records\n",
      "Loaded 2025-02: 3,577,543 records\n",
      "Loaded 2025-03: 4,145,257 records\n",
      "Loaded 2025-04: 3,970,553 records\n",
      "Loaded 2025-05: 4,591,845 records\n",
      "Loaded 2025-06: 4,322,960 records\n",
      "Total Yellow Taxi 2025 Records: 24,083,384\n",
      "Loaded 2025-01: 48,326 records\n",
      "Loaded 2025-02: 46,621 records\n",
      "Loaded 2025-03: 51,539 records\n",
      "Loaded 2025-04: 52,132 records\n",
      "Loaded 2025-05: 55,399 records\n",
      "Loaded 2025-06: 49,390 records\n",
      "Total Green Taxi 2025 Records: 303,407\n"
     ]
    }
   ],
   "source": [
    "# Load 2025 taxi data (Jan-June)\n",
    "months_2025 = ['2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06']\n",
    "\n",
    "# Load and union all yellow taxi data for 2025\n",
    "yellow_dataframes_2025 = []\n",
    "for month in months_2025:\n",
    "    try:\n",
    "        df = spark.read.parquet(f'../data/raw/taxi_2025/yellow_tripdata_{month}.parquet')\n",
    "        df = df.withColumn(\"data_month\", lit(month))\n",
    "        yellow_dataframes_2025.append(df)\n",
    "        print(f\"Loaded {month}: {df.count():,} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {month}: {str(e)}\")\n",
    "\n",
    "yellow_2025 = yellow_dataframes_2025[0]\n",
    "for df in yellow_dataframes_2025[1:]:\n",
    "    yellow_2025 = yellow_2025.union(df)\n",
    "\n",
    "print(f\"Total Yellow Taxi 2025 Records: {yellow_2025.count():,}\")\n",
    "\n",
    "# Load and union all green taxi data for 2025\n",
    "green_dataframes_2025 = []\n",
    "for month in months_2025:\n",
    "    try:\n",
    "        df = spark.read.parquet(f'../data/raw/taxi_2025/green_tripdata_{month}.parquet')\n",
    "        df = df.withColumn(\"data_month\", lit(month))\n",
    "        green_dataframes_2025.append(df)\n",
    "        print(f\"Loaded {month}: {df.count():,} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {month}: {str(e)}\")\n",
    "\n",
    "green_2025 = green_dataframes_2025[0]\n",
    "for df in green_dataframes_2025[1:]:\n",
    "    green_2025 = green_2025.union(df)\n",
    "\n",
    "print(f\"Total Green Taxi 2025 Records: {green_2025.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0a76d",
   "metadata": {},
   "source": [
    "## Apply Same Data Cleaning as 2024 Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6403e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning 2025 data:\n",
      "  Yellow: 23,903,476 (99.3%)\n",
      "  Green: 298,835 (98.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed passenger count nulls: Yellow=1, Green=1\n"
     ]
    }
   ],
   "source": [
    "# Apply identical cleaning logic from training data\n",
    "def clean_taxi_data(df, pickup_col, dropoff_col, datetime_col):\n",
    "    return df.filter(\n",
    "        (col(\"PULocationID\") >= 1) & (col(\"PULocationID\") <= 263) &\n",
    "        (col(\"DOLocationID\") >= 1) & (col(\"DOLocationID\") <= 263) &\n",
    "        col(\"PULocationID\").isNotNull() & col(\"DOLocationID\").isNotNull() &\n",
    "        (col(\"trip_distance\") >= 0) & (col(\"trip_distance\") <= 100) &\n",
    "        col(datetime_col).isNotNull()\n",
    "    )\n",
    "\n",
    "# Clean 2025 datasets\n",
    "yellow_2025_clean = clean_taxi_data(yellow_2025, \"PULocationID\", \"DOLocationID\", \"tpep_pickup_datetime\")\n",
    "green_2025_clean = clean_taxi_data(green_2025, \"PULocationID\", \"DOLocationID\", \"lpep_pickup_datetime\")\n",
    "\n",
    "yellow_2025_clean_count = yellow_2025_clean.count()\n",
    "green_2025_clean_count = green_2025_clean.count()\n",
    "\n",
    "print(f\"After cleaning 2025 data:\")\n",
    "print(f\"  Yellow: {yellow_2025_clean_count:,} ({yellow_2025_clean_count/yellow_2025.count()*100:.1f}%)\")\n",
    "print(f\"  Green: {green_2025_clean_count:,} ({green_2025_clean_count/green_2025.count()*100:.1f}%)\")\n",
    "\n",
    "# Handle passenger count nulls (same as training data)\n",
    "yellow_median = yellow_2025_clean.select(expr(\"percentile_approx(passenger_count, 0.5)\")).collect()[0][0]\n",
    "green_median = green_2025_clean.select(expr(\"percentile_approx(passenger_count, 0.5)\")).collect()[0][0]\n",
    "\n",
    "yellow_median = int(yellow_median) if yellow_median else 1\n",
    "green_median = int(green_median) if green_median else 1\n",
    "\n",
    "yellow_2025_clean = yellow_2025_clean.fillna({\"passenger_count\": yellow_median})\n",
    "green_2025_clean = green_2025_clean.fillna({\"passenger_count\": green_median})\n",
    "\n",
    "print(f\"Imputed passenger count nulls: Yellow={yellow_median}, Green={green_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03049cb8",
   "metadata": {},
   "source": [
    "## Aggregate to Daily Zone Level (Same as Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ea8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 daily zone aggregation: 43,433 zone-day records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:=============> (44 + 4) / 48][Stage 119:=====>           (2 + 4) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 date range: 2007-12-05 to 2025-07-01\n",
      "2025 zones with activity: 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Aggregate yellow taxi to daily zone level\n",
    "yellow_2025_daily = yellow_2025_clean.select(\n",
    "    col(\"PULocationID\").alias(\"LocationID\"),\n",
    "    date_format(\"tpep_pickup_datetime\", \"yyyy-MM-dd\").alias(\"date\"),\n",
    "    col(\"trip_distance\"),\n",
    "    col(\"passenger_count\")\n",
    ").groupBy(\"LocationID\", \"date\").agg(\n",
    "    count(\"*\").alias(\"trip_count\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_trip_distance\"),\n",
    "    sum(\"passenger_count\").alias(\"total_passengers\")\n",
    ").withColumn(\"taxi_type\", lit(\"yellow\"))\n",
    "\n",
    "# Aggregate green taxi to daily zone level  \n",
    "green_2025_daily = green_2025_clean.select(\n",
    "    col(\"PULocationID\").alias(\"LocationID\"),\n",
    "    date_format(\"lpep_pickup_datetime\", \"yyyy-MM-dd\").alias(\"date\"),\n",
    "    col(\"trip_distance\"), \n",
    "    col(\"passenger_count\")\n",
    ").groupBy(\"LocationID\", \"date\").agg(\n",
    "    count(\"*\").alias(\"trip_count\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_trip_distance\"),\n",
    "    sum(\"passenger_count\").alias(\"total_passengers\")\n",
    ").withColumn(\"taxi_type\", lit(\"green\"))\n",
    "\n",
    "# Combine yellow and green daily data\n",
    "combined_2025_daily = yellow_2025_daily.union(green_2025_daily)\n",
    "\n",
    "# Aggregate both taxi types to single daily zone level\n",
    "daily_zone_2025 = combined_2025_daily.groupBy(\"LocationID\", \"date\").agg(\n",
    "    sum(\"trip_count\").alias(\"daily_trips\"),\n",
    "    avg(\"avg_trip_distance\").alias(\"avg_distance\"),\n",
    "    sum(\"total_passengers\").alias(\"daily_passengers\")\n",
    ").withColumn(\"date\", to_date(col(\"date\")))\n",
    "\n",
    "print(f\"2025 daily zone aggregation: {daily_zone_2025.count():,} zone-day records\")\n",
    "\n",
    "# Check aggregation results\n",
    "date_range_2025 = daily_zone_2025.select(min(\"date\"), max(\"date\")).collect()[0]\n",
    "zone_coverage_2025 = daily_zone_2025.select(count_distinct(\"LocationID\")).collect()[0][0]\n",
    "print(f\"2025 date range: {date_range_2025[0]} to {date_range_2025[1]}\")\n",
    "print(f\"2025 zones with activity: {zone_coverage_2025}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89611a62",
   "metadata": {},
   "source": [
    "## Add Temporal Features (Same as Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f008334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added temporal features for 2025 data\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofweek, dayofmonth, weekofyear\n",
    "# Add identical temporal features as training data\n",
    "daily_2025_with_temporal = daily_zone_2025.withColumn(\"year\", year(\"date\")) \\\n",
    "    .withColumn(\"month\", month(\"date\")) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(\"date\")) \\\n",
    "    .withColumn(\"day_of_month\", dayofmonth(\"date\")) \\\n",
    "    .withColumn(\"week_of_year\", weekofyear(\"date\")) \\\n",
    "    .withColumn(\"is_weekend\", when(col(\"day_of_week\").isin([1, 7]), 1).otherwise(0))\n",
    "\n",
    "print(\"Added temporal features for 2025 data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98101216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/15 14:36:18 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 133:=====================================================> (47 + 1) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "|summary|       LocationID|       daily_trips|     avg_distance|  daily_passengers|               year|             month|      day_of_week|      day_of_month|      week_of_year|        is_weekend|\n",
      "+-------+-----------------+------------------+-----------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "|  count|            43433|             43433|            43433|             43433|              43433|             43433|            43433|             43433|             43433|             43433|\n",
      "|   mean|133.1910528860544|   557.23323279534|5.038081063216802| 684.3585983008312| 2024.9983652982755| 3.534432344070177|4.004466649782423|15.633757741809223|13.804595584002946|0.2885824142932793|\n",
      "| stddev|76.18904211380763|1194.1989426586636|3.038680165521391|1498.8326616931333|0.14046110682765464|1.7170359040392535|2.006924909718331| 8.736394026995866| 7.462703671809273|0.4531085206033548|\n",
      "|    min|                1|                 1|              0.0|                 0|               2007|                 1|                1|                 1|                 1|                 0|\n",
      "|    max|              263|              9570|         49.79875|             11566|               2025|                12|                7|                31|                52|                 1|\n",
      "+-------+-----------------+------------------+-----------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "daily_2025_with_temporal.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d124ba",
   "metadata": {},
   "source": [
    "Removing years outside of 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c884ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:===================================================>   (45 + 3) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filtering: 43,433 records, after filtering: 43,409 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_daily = daily_2025_with_temporal.filter(col(\"year\") == 2025)\n",
    "\n",
    "print(f\"before filtering: {daily_2025_with_temporal.count():,} records, after filtering: {filtered_daily.count():,} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa95e86",
   "metadata": {},
   "source": [
    "## Load and Integrate External Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "797afed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 weather data: 181 days\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 2025 integrated dataset: 114,380 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 205:=====================================================> (47 + 1) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 integration quality:\n",
      "  Missing weather: 6\n",
      "  Missing census: 334\n",
      "  Missing zone info: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load preprocessed external data (same as training)\n",
    "weather_df = spark.read.parquet(\"../data/processed/weather_data.parquet\")\n",
    "census_df = spark.read.parquet(\"../data/processed/census_data.parquet\")\n",
    "zones_df = spark.read.parquet(\"../data/processed/taxi_zones.parquet\")\n",
    "# Filter weather data for 2025 period\n",
    "weather_2025 = weather_df.filter(\n",
    "    (col(\"date\") >= \"2025-01-01\") & (col(\"date\") <= \"2025-06-30\")\n",
    ")\n",
    "\n",
    "print(f\"2025 weather data: {weather_2025.count()} days\")\n",
    "\n",
    "# Join with weather data\n",
    "daily_2025_with_weather = filtered_daily.join(weather_2025, \"date\", \"left\")\n",
    "\n",
    "# Join with census data\n",
    "daily_2025_with_census = daily_2025_with_weather.join(census_df, \"LocationID\", \"left\")\n",
    "\n",
    "# Join with zone information\n",
    "final_2025_data = daily_2025_with_census.join(\n",
    "    zones_df.select(\"LocationID\", \"Zone\", \"Borough\", \"service_zone\"), \n",
    "    \"LocationID\", \"left\"\n",
    ")\n",
    "\n",
    "print(f\"Final 2025 integrated dataset: {final_2025_data.count():,} records\")\n",
    "\n",
    "# Check integration success\n",
    "integration_stats_2025 = final_2025_data.select(\n",
    "    sum(col(\"temperature_avg\").isNull().cast(\"int\")).alias(\"missing_weather\"),\n",
    "    sum(col(\"Median_Income\").isNull().cast(\"int\")).alias(\"missing_census\"),\n",
    "    sum(col(\"Zone\").isNull().cast(\"int\")).alias(\"missing_zone_info\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"2025 integration quality:\")\n",
    "print(f\"  Missing weather: {integration_stats_2025['missing_weather']}\")\n",
    "print(f\"  Missing census: {integration_stats_2025['missing_census']}\")\n",
    "print(f\"  Missing zone info: {integration_stats_2025['missing_zone_info']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beef5c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 229:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------+------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+---------------------+------------------+--------------------+-------------+------------+\n",
      "|summary|       LocationID|       daily_trips|      avg_distance|  daily_passengers|  year|             month|      day_of_week|      day_of_month|      week_of_year|         is_weekend|   temperature_avg|  precipitation_mm|           snow_mm|    Median_Income|Percent_No_Vehicle|No_Vehicle_Households|  Total_Households|                Zone|      Borough|service_zone|\n",
      "+-------+-----------------+------------------+------------------+------------------+------+------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+---------------------+------------------+--------------------+-------------+------------+\n",
      "|  count|           114380|            114380|            114380|            114380|114380|            114380|           114380|            114380|            114380|             114380|            114374|            114374|            114374|           114046|            114046|               114046|            114046|              114380|       114380|      114380|\n",
      "|   mean|128.6780381185522|493.85431019408986| 4.983223711194517| 607.3519496415457|2025.0|3.5259923063472636|4.005341842979542|15.625493967476832|13.791230984437838|0.28806609547123624|10.884166856103306|2.9322914298705673| 0.295355587808418|84792.21710537853|  55.5842903235226|    36011.07641653368| 62819.82138786104|                NULL|         NULL|        NULL|\n",
      "| stddev|74.82355148801292| 1142.001363190092|2.8163892961618435|1441.1612127637354|   0.0|1.7071039434459803|2.005852949079505| 8.733128228255795| 7.455969369974068| 0.4528640117439375|  8.98314733100547| 5.982229379344556|1.1366066902925436|36510.17821319029|19.930015142159384|   19565.256704128333|17993.106633010633|                NULL|         NULL|        NULL|\n",
      "|    min|                1|                 1|               0.0|                 0|  2025|                 1|                1|                 1|                 1|                  0|              -8.2|               0.0|               0.0|            32428| 7.929810116811609|                 4623|             37549|Allerton/Pelham G...|        Bronx|    Airports|\n",
      "|    max|              263|              9570|          49.79875|             11566|  2025|                 7|                7|                31|                27|                  1|              33.2|              28.3|               8.0|           171480| 84.54381014398379|                83928|            108958|      Yorkville West|Staten Island| Yellow Zone|\n",
      "+-------+-----------------+------------------+------------------+------------------+------+------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+---------------------+------------------+--------------------+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_2025_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae42ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_final_2025 = final_2025_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c392ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+------+------------------+------------------+------------------+-----------------+-------------------+------------------+------------------+------------------+------------------+------------------+---------------------+----------------+--------------------+-------------+------------+\n",
      "|summary|        LocationID|      daily_trips|      avg_distance|  daily_passengers|  year|             month|       day_of_week|      day_of_month|     week_of_year|         is_weekend|   temperature_avg|  precipitation_mm|           snow_mm|     Median_Income|Percent_No_Vehicle|No_Vehicle_Households|Total_Households|                Zone|      Borough|service_zone|\n",
      "+-------+------------------+-----------------+------------------+------------------+------+------------------+------------------+------------------+-----------------+-------------------+------------------+------------------+------------------+------------------+------------------+---------------------+----------------+--------------------+-------------+------------+\n",
      "|  count|            114040|           114040|            114040|            114040|114040|            114040|            114040|            114040|           114040|             114040|            114040|            114040|            114040|            114040|            114040|               114040|          114040|              114040|       114040|      114040|\n",
      "|   mean|128.97944580848824|495.3011399508944| 4.988144193395733|   609.12216766047|2025.0|3.5255875131532797| 4.005366538056822|15.626122413188355|13.78958260259558| 0.2880568221676605|10.883094528235361|2.9320370045599455|0.2954138898632059|  84793.3465275342| 55.58393588405343|   36011.039950894425|62819.9319449316|                NULL|         NULL|        NULL|\n",
      "| stddev| 74.71395234836827|1143.394516274373|2.8116110839567177|1442.9425426728235|   0.0|1.7070228841482562|2.0058375415080705| 8.732789479413281|7.455808315165701|0.45285967771845775| 8.983055541266934| 5.981845096480092|1.1368022286738064|36510.661624794906|19.929753139348094|     19565.4902448965|17993.3044352203|                NULL|         NULL|        NULL|\n",
      "|    min|                 2|                1|               0.0|                 0|  2025|                 1|                 1|                 1|                1|                  0|              -8.2|               0.0|               0.0|             32428| 7.929810116811609|                 4623|           37549|Allerton/Pelham G...|        Bronx|    Airports|\n",
      "|    max|               263|             9570|          49.79875|             11566|  2025|                 6|                 7|                31|               27|                  1|              33.2|              28.3|               8.0|            171480| 84.54381014398379|                83928|          108958|      Yorkville West|Staten Island| Yellow Zone|\n",
      "+-------+------------------+-----------------+------------------+------------------+------+------------------+------------------+------------------+-----------------+-------------------+------------------+------------------+------------------+------------------+------------------+---------------------+----------------+--------------------+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clean_final_2025.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59187f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create identical features as training data\n",
    "clean_final_2025 = clean_final_2025 \\\n",
    "    .withColumn(\"vehicle_ownership_rate\", 1 - col(\"Percent_No_Vehicle\") / 100) \\\n",
    "    .withColumn(\"log_income\", log(col(\"Median_Income\") + 1)) \\\n",
    "    .withColumn(\"has_precipitation\", when(col(\"precipitation_mm\") > 0, 1).otherwise(0)) \\\n",
    "    .withColumn(\"has_snow\", when(col(\"snow_mm\") > 0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aa11b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clean_final_2025.write.mode(\"overwrite\").parquet(\"../data/processed/taxi_2025_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f53549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
